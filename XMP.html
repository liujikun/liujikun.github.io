<!DOCTYPE html>
<html lang="en">
	<head>
        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-138977761-1"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());

          gtag('config', 'UA-138977761-1');
        </script>

		<title>XMP-Font</title>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

		<link href="https://fonts.googleapis.com/css?family=Poppins:300,400,500,600,700" rel="stylesheet">
		<link href="https://fonts.googleapis.com/css?family=Montserrat:300,400,500,700" rel="stylesheet">

		<link rel="stylesheet" href="css/open-iconic-bootstrap.min.css">
		<link rel="stylesheet" href="css/animate.css">
		<!-- <link rel="stylesheet" href="css/main.css" /> -->
		<link rel="stylesheet" href="css/owl.carousel.min.css">
		<link rel="stylesheet" href="css/owl.theme.default.min.css">
		<link rel="stylesheet" href="css/magnific-popup.css">

		<link rel="stylesheet" href="css/aos.css">

		<link rel="stylesheet" href="css/ionicons.min.css">

		<link rel="stylesheet" href="css/bootstrap-datepicker.css">
		<link rel="stylesheet" href="css/jquery.timepicker.css">
		<link rel="stylesheet" href="css/academicons.min.css"/>
		<link rel="stylesheet" href="css/academicons.css"/>
		<link rel="stylesheet" href="css/flaticon.css">
		<link rel="stylesheet" href="css/icomoon.css">
		<link rel="stylesheet" href="css/style.css">
	</head>


	<body>
	<div id="coolib-page">


		<!-- Main page -->
		<div id="coolib-main">


            <!-- Front page -->
            <div id='front' class="hero-wrap" style="background-color: white " data-stellar-background-ratio="0.5">
				<div class="overlay"></div>
				<div class="container title d-flex justify-content-center">
					<div class="col-md-12 text text-center">
						<div class="desc">
							<h1 class="mb-4">XMP-Font: Self-Supervised Cross-Modality Pre-training for Few-Shot Font Generation</h1>
							<div class="authors">
								<a class="name" href="https://liujikun.github.io">Wei Liu</a>
								<a class="name" href="">Fangyue Liu</a>
								<a class="name" href="">Fei Ding</a>
                                <a class="name" href="">Qian He</a>
                                <a class="name" href="">Zili Yi</a>
								<p class="organization">ByteDance</p>
								<p class="publication">CVPR 2022</p>
							</div>
							<!-- <div class="authors">CVPR 2022</div> -->
							<a class="btn btn-primary" href="https://arxiv.org/abs/2204.05084" target=”_blank”>
										<svg class="svg-inline--fa fa-file-pdf fa-w-12" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-pdf" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512" data-fa-i2svg=""><path fill="currentColor" d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z"></path></svg>
							Paper</a>
							<a class="btn btn-primary disabled" href="https://github.com/liujikun/XMP-Font" target=”_blank”>
                    <svg class="svg-inline--fa fa-github fa-w-16" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" data-fa-i2svg=""><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg><!-- <i class="fab fa-github"></i> Font Awesome fontawesome.com -->
							Code</a>
						</div>
					</div>
				</div>
            </div>
            


			<!-- Publication -->
			<section class="ftco-section">
				<div id='projects' class="container">
					<div class="row justify-content-center mb-5 pb-2">
						<div class="col-md-7 heading-section text-center ftco-animate">
							<h2 class="mb-4">Projects</h2>
						</div>
					</div>
					<div class="row">

						<div class="col-md-6">
							<div class="blog-entry ftco-animate">
								<div class='img-box'><div href="#" class="img img-2" style="background-image: url(images/XMP-font-demo1.gif);
									background-size: 100%;"></div></div>
								<div class="text text-2 pt-2 mt-3">
									<span class="category mb-3 d-block">Font Generative, Multimodal Generation</span>
									<h5>XMP-Font: Self-Supervised Cross-Modality Pre-training for Few-Shot Font Generation</h5>
									<p><span class='me'>Wei Liu</span>, Fangyue Liu, Fei Ding, Qian He, Zili Yi</p>
									<p>in CVPR, 2022 </p>
									<div class="meta-wrap">
											<p class="meta">
												<span><a target="_blank" href="https://arxiv.org/pdf/2204.05084.pdf">pdf</a></span>
												<span><a target="_blank" href="https://github.com/liujikun/XMP-Font">github</a></span>
												<span><a href="single.html">details</a></span>
											</p>
									</div>
								</div>
							</div>
						</div><!-- END Entry -->
						<div class="col-md-6">
							<div class="blog-entry ftco-animate">
								<div class='img-box'><div href="#" class="img img-2" style="background-image: url(images/denoising.png);
									background-size: 100%;"></div></div>
								<div class="text text-2 pt-2 mt-3">
									<span class="category mb-3 d-block">Image Enhancement, Denoising</span>
									<h5>Densely self-guided wavelet network for image denoising</h5>
									<p><span class='me'>Wei Liu</span>, Yuzhi Zhao, Qiong Yan</p>
									<p>in CVPR Workshop, 2020</p>
									<div class="meta-wrap">
											<p class="meta">
												<span><a target="_blank" href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w31/Liu_Densely_Self-Guided_Wavelet_Network_for_Image_Denoising_CVPRW_2020_paper.pdf">pdf</a></span>
												<span><a target="_blank" href="
													https://github.com/liujikun/Densely-Self-guided-Wavelet-Network-for-Image-Denoising">github</a></span>
											</p>
									</div>
								</div>
							</div>
						</div><!-- END Entry -->
						

					</div>
				</div>




			<!-- Experience -->
				<div id='experience' class="container">
					<div class="row justify-content-center mb-5 pb-2">
						<div class="col-md-7 heading-section text-center ftco-animate">
							<h2 class="mb-4">Experience</h2>
						</div>
					</div>
					<div class="row">

						<div class="col-md-3">
							<div class="blog-entry ftco-animate">
								<a target="_blank" href="https://www.hit.edu.cn/"><div href="#" class="img img-3" style="background-image: url(images/hit.jpeg);
									background-size: 200px;"></div></a>
								<div class="text text-2 pt-2 mt-3">
									<span class="category mb-3 d-block">Education</span>
									<h5>Harbin Institute of Technology</h5>
									<p><span class='me'>Bachelor, PhD, 2012-2020</p>
									<p>Topic: Image Generation, Domain Adaptation, Semantic Segmentation</p>
								</div>
							</div>
						</div><!-- END Entry -->

						<div class="col-md-3">
							<div class="blog-entry ftco-animate">
								<a target="_blank" href="https://www.sensetime.com/cn"><div href="#" class="img img-3" style="background-image: url(images/sensetime.jpeg);
									background-size: 200px;"></div></a>
								<div class="text text-2 pt-2 mt-3">
									<span class="category mb-3 d-block">Internship</span>
									<h5>SenseTime MIG</h5>
									<p><span class='me'>Research Intern, 2019-2020</p>
									<p>Topic: Image Enhancement, Image Denoising, Image Deglow, Image Generation</p>
								</div>
							</div>
						</div><!-- END Entry -->

						<div class="col-md-3">
							<div class="blog-entry ftco-animate">
								<a target="_blank" href="https://www.bytedance.com/"><div href="#" class="img img-3" style="background-image: url(images/bytedance.jpg);
									background-size: 200px;"></div></a>
								<div class="text text-2 pt-2 mt-3">
									<span class="category mb-3 d-block">Research Scientist</span>
									<h5>ByteDance Inc.</h5>
									<p><span class='me'>2020 to present</p>
									<p>Topic: Content Generation, Multimodal Generation, Smart Editing, Smart Design</p>
								</div>
							</div>
						</div><!-- END Entry -->

						<div class="col-md-3">
							<div class="blog-entry ftco-animate">
								<a target="_blank" href="https://www.osu.edu/"><div href="#" class="img img-3" style="background-image: url(images/OSU.png);
									background-size: 200px;"></div></a>
								<div class="text text-2 pt-2 mt-3">
									<span class="category mb-3 d-block">Education</span>
									<h5>The Ohio State University</h5>
									<p><span class='me'>Visiting student, 2017-2019</p>
									<p>Topic: Domain Adaptation, Stereo Matching, Semantic Segmentation</p>
								</div>
							</div>
						</div><!-- END Entry -->

					</div>
				</div>

				<div id='publications' class="container">
					<div class="row justify-content-center mb-5 pb-2">
						<div class="col-md-7 heading-section text-center ftco-animate">
							<h2 class="mb-4">Publications</h2>
						</div>
					</div>
					<div class="row">

						<div id="wrapper">
							<section id="item10" class="item">

			
								<h2><font size = "5">Image Generation</font></h2>
								<p>
									<ul>
										<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://arxiv.org/pdf/2204.05084.pdf">XMP-Font: Self-Supervised Cross-Modality Pre-training for Few-Shot Font Generation</a></span><br/>
											<u>Wei Liu</u>, Fangyue Liu, Fei Ding, Qian He, Zili Yi<br><span style="color:#3D3D3D">The IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR) 2022</span></li>
									</ul>
									<ul>
										<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://arxiv.org/pdf/2203.00386.pdf">CLIP-GEN: Language-Free Training of a Text-to-Image Generator with CLIP</a></span><br/>
											Zihao Wang, <u>Wei Liu</u>,, Qian He, Xinglong Wu, Zili Yi<br><span style="color:#3D3D3D">Submitted to ECCV 2022 &nbsp <a target="_blank" href="https://mp.weixin.qq.com/s/UAAVTI9zVhRDcMwUSW5l_Q">量子位报道</a></span></li>
									</ul>
									<ul>
										<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="">CFFT-GAN: Cross-domain Feature Fusion Transformer for Exemplar-based Image Translation</a></span><br/>
											Tianxiang Ma, Bingchuan Li, <u>Wei Liu</u>, Miao Hua, Jing Dong, Tieniu Tan<br><span style="color:#3D3D3D">Submitted to ECCV 2022</span></li>
									</ul>
									<ul>
										<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="">ReGANIE: Rectifying GAN Inversion Errors for Accurate Real Image Editing</a></span><br/>
											Bingchuan Li, Tianxiang Ma, Peng Zhang, Miao Hua, <u>Wei Liu</u>, Qian He, Zili Yi<br><span style="color:#3D3D3D">Submitted to ECCV 2022</span></li>
									</ul>
									<ul>
										<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://arxiv.org/pdf/2109.10737.pdf">DyStyle: Dynamic Neural Network for Multi-Attribute-Conditioned Style Editing</a></span><br/>
											Bingchuan Li, Shaofei Cai, <u>Wei Liu</u>, Peng Zhang, Miao Hua, Qian He, Zili Yi<br><span style="color:#3D3D3D">Submitted to IJCAI 2022</span></li>
									</ul>
									<ul>
										<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://arxiv.org/pdf/2204.09962.pdf">ChildPredictor: A Child Face Prediction Framework with Disentangled Learning</a></span><br>
											Yuzhi Zhao, Lai-Man Po, Xuehui Wang, Qiong Yan, Wei Shen, Yujia Zhang, <u>Wei Liu</u>, Chun-Kit Wong, Chiu-Sing Pang, Weifeng Ou, Wing Yin Yu, Buhua Liu<br><span style="color:#3D3D3D">IEEE Transactions on Multimedia, 2022 (IF=6.51)</span></li>
									</ul>
								</p>
							</section>
								<section id="item9" class="item">
			
									<h2><font size = "5">Image Enhancement</font></h2>
									<p>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w31/Liu_Densely_Self-Guided_Wavelet_Network_for_Image_Denoising_CVPRW_2020_paper.pdf">Densely self-guided wavelet network for image denoising</a></span><br/>
											<u>Wei Liu</u>, Qiong Yan, Yuzhi Zhao<br><span style="color:#3D3D3D">The IEEE / CVF Computer Vision and Pattern Recognition Conference Workshop (CVPRW) 2020</span></li>
			
			
										</ul>
									</p>
								</section>
								<section id="item8" class="item">
									<h2><font size = "5">Domain Adaptation</font></h2>
			
									<p>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://www.researchgate.net/profile/Rongjun-Qin/publication/347005550_Bispace_Domain_Adaptation_Network_for_Remotely_Sensed_Semantic_Segmentation/links/5fe3b5c845851553a0e62dd6/Bispace-Domain-Adaptation-Network-for-Remotely-Sensed-Semantic-Segmentation.pdf">Bispace domain adaptation network for remotely sensed semantic segmentation</a></span><br>
											<u>Wei Liu</u>, Fulin Su, Xinfei Jin, Hongxu Li, Rongjun Qin<br><span style="color:#3D3D3D">IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, 2020 (IF=6.87)</span></li>
										</ul>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://ieeexplore.ieee.org/abstract/document/8960415">	
												A multikernel domain adaptation method for unsupervised transfer learning on cross-source and cross-region remote sensing data classification</a></span><br>
											<u>Wei Liu</u>, Rongjun Qin<br><span style="color:#3D3D3D">IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, 2020 (IF=6.87)</span></li>
										</ul>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://www.tandfonline.com/doi/abs/10.1080/01431161.2020.1736727">	
												A novel unsupervised adversarial domain adaptation network for remotely sensed scene classification</a></span><br>
											<u>Wei Liu</u>, Fulin Su<br><span style="color:#3D3D3D">International Journal of Remote Sensing, 2020 (IF=3.36)</span></li>
										</ul>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://ieeexplore.ieee.org/abstract/document/8932673">	
												Unsupervised Adversarial Domain Adaptation Network for Semantic Segmentation</a></span><br>
											<u>Wei Liu</u>, Fulin Su<br><span style="color:#3D3D3D">IEEE Geoscience and Remote Sensing Letters, 2019 (IF=5.14)</span></li>
										</ul>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://www.tandfonline.com/doi/abs/10.1080/2150704X.2019.1597295">	
												Weakly supervised classification of time-series of very high resolution remote sensing images by transfer learning</a></span><br>
											<u>Wei Liu</u>, Rongjun Qin, Fulin Su<br><span style="color:#3D3D3D">Remote Sensing Letters, 2019 (IF=2.91)</span></li>
										</ul>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://www.researchgate.net/profile/Rongjun-Qin/publication/325256383_An_Unsupervised_Domain_Adaptation_Method_for_Multi-Modal_Remote_Sensing_Image_Classification/links/5c194c72a6fdccfc705813ed/An-Unsupervised-Domain-Adaptation-Method-for-Multi-Modal-Remote-Sensing-Image-Classification.pdf">	
												An unsupervised domain adaptation method for multi-modal remote sensing image classification</a></span><br>
											<u>Wei Liu</u>, Rongjun Qin, Fulin Su, Kun Hu<br><span style="color:#3D3D3D">2018 26th International Conference on Geoinformatics (Best Student Paper 3rd plcae)</span></li>
										</ul>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://ieeexplore.ieee.org/abstract/document/8898334">	
												Unsupervised Transfer Learning Using for Multi-Model Remote Sensing Data Classification</a></span><br>
											<u>Wei Liu</u>, Rongjun Qin<br><span style="color:#3D3D3D">IEEE International Geoscience and Remote Sensing Symposium (IGARSS) 2019</span></li>
										</ul>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://ieeexplore.ieee.org/abstract/document/9547210">	
												Large-Scale Land Cover Mapping of Satellite Images Using Ensemble of Random Forests — IEEE Data Fusion Contest 2020 Track 1</a></span><br>
											Huijun Chen, <u>Wei Liu</u>, Changlin Xiao, Rongjun Qin<br><span style="color:#3D3D3D">IEEE International Geoscience and Remote Sensing Symposium (IGARSS) 2020</span></li>
										</ul>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://ieeexplore.ieee.org/abstract/document/9547214">	
												Large-Scale Land Cover Mapping of Satellite Images Using Ensemble of Random Forests with Multi-Resolution Label–IEEE Data Fusion Contest 2020 Track 2</a></span><br>
											Huijun Chen, Changlin Xiao, <u>Wei Liu</u>, Rongjun Qin<br><span style="color:#3D3D3D">IEEE International Geoscience and Remote Sensing Symposium (IGARSS) 2020</span></li>
										</ul>
									</p>
								</section>
			
								<section id="item7" class="item">
									<h2><font size = "5">Stereo Matching</font></h2>
									<p>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://www.tandfonline.com/doi/abs/10.1080/2150704X.2020.1723168">A window size selection network for stereo dense image matching</a></span><br/>
											Xu Huang, <u>Wei Liu</u> (The first two authors contributed equally), Rongjun Qin<br><span style="color:#3D3D3D">International Journal of Remote Sensing, 2020 (IF=3.36)</span></li>
										</ul>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://www.mdpi.com/2072-4292/12/19/3138">Stereo dense image matching by adaptive fusion of multiple-window matching results</a></span><br/>
												Yilong Han, <u>Wei Liu</u> , Xu Huang, Shugen Wang, Rongjun Qin<br><span style="color:#3D3D3D">Remote Sensing, 2020 (IF=4.85)</span></li>
										</ul>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://ieeexplore.ieee.org/abstract/document/8900588">Semantic 3D reconstruction using multi-view high-resolution satellite images based on U-Net and image-guided depth fusion</a></span><br/>
												Rongjun Qin, Xu Huang, <u>Wei Liu</u>, Changlin Xiao<br><span style="color:#3D3D3D">IEEE International Geoscience and Remote Sensing Symposium (IGARSS) 2019</span></li>
										</ul>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://ieeexplore.ieee.org/abstract/document/8900262">Pairwise stereo image disparity and semantics estimation with the combination of U-Net and pyramid stereo matching network</a></span><br/>
												Rongjun Qin, Xu Huang, <u>Wei Liu</u>, Changlin Xiao<br><span style="color:#3D3D3D">IEEE International Geoscience and Remote Sensing Symposium (IGARSS) 2019</span></li>
										</ul>
									</p>
								</section>
								<section id="item6" class="item">
									<h2><font size = "5">Others</font></h2>
									<p>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://www.researchgate.net/profile/Xi-Chen-311/publication/317129244_Semisupervised_Multiview_Feature_Selection_for_VHR_Remote_Sensing_Images_With_Label_Learning_and_Automatic_View_Generation/links/5a75cd6345851541ce58735b/Semisupervised-Multiview-Feature-Selection-for-VHR-Remote-Sensing-Images-With-Label-Learning-and-Automatic-View-Generation.pdf">Semisupervised multiview feature selection for VHR remote sensing images with label learning and automatic view generation</a></span><br/>
												Xi Chen, <u>Wei Liu</u>, Fulin Su, Gongjian Zhou<br><span style="color:#3D3D3D">IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2017 (IF=4.54)</span></li>
										</ul>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://ieeexplore.ieee.org/abstract/document/7729612">Semi-supervised multiview feature selection with label learning for VHR remote sensing images</a></span><br/>
												Xi Chen, <u>Wei Liu</u>, Fulin Su, Guofan Shao<br><span style="color:#3D3D3D">IEEE International Geoscience and Remote Sensing Symposium (IGARSS) 2016</span></li>
										</ul>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w31/Zhao_Hierarchical_Regression_Network_for_Spectral_Reconstruction_From_RGB_Images_CVPRW_2020_paper.pdf">Hierarchical regression network for spectral reconstruction from RGB images</a></span><br/>
												Yuzhi Zhao, Lai-Man Po, Qiong Yan, <u>Wei Liu</u>, Tingyu Lin<br><span style="color:#3D3D3D">The IEEE / CVF Computer Vision and Pattern Recognition Conference Workshop (CVPRW) 2020</span></li>
										</ul>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://ieeexplore.ieee.org/abstract/document/8557172">High-frequency jitter detection by registration error curve of high-resolution multi-spectral satellite image</a></span><br/>
												Kun Hu, Yongjun Zhang, <u>Wei Liu</u><br><span style="color:#3D3D3D">2018 26th International Conference on Geoinformatics</span></li>
										</ul>
									</p>
								</section>
								</section>
			
						</div>
						

					</div>
				</div>
			</section>

			<!-- Footer -->
			<footer id='footer' class="ftco-footer ftco-bg-dark ftco-section">
				<div class="container px-md-5">
					<div class="row mb-5">
						<div class="col-md">
							<div class="ftco-footer-widget mb-4 ml-md-4">
								<h2 class="ftco-heading-2">Category</h2>
								<ul class="list-unstyled categories">
									<li><a href="#front">Home </a></li>
									<li><a href="#projects">Projects </a></li>
									<li><a href="#experience">Experience </a></li>
									<li><a href="#pubications">Pubications </a></li>
									<li><a href="#footer">Contact </a></li>
								</ul>
							</div>
						</div>
						<div class="col-md">
						</div>
						<div class="col-md">
							<div class="ftco-footer-widget mb-4">
								<h2 class="ftco-heading-2">Have a Questions?</h2>
								<div class="block-23 mb-3">
									<ul>
										<li><span class="icon icon-map-marker"></span>
											<p>BeiJing, China</p>
										</li>
										<!-- <li><a href="#"><span class="icon icon-phone"></span><span class="text">+1 517 220 8402</span></a></li> -->
										<li><a href="#"><span class="icon icon-envelope"></span><span class="text">liuwei.jikun@bytedance.com</span></a></li>
										<li><a href="#"><span class="icon icon-envelope"></span><span class="text">liujikun63@gmail.com</span></a></li>
									</ul>
								</div>
							</div>
						</div>
					</div>
					<div class="row">
						<div class="col-md-12">

							<p><!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
		Copyright &copy;<script>document.write(new Date().getFullYear());</script> All rights reserved | This template is made with <i class="icon-heart" aria-hidden="true"></i> by <a target="_blank" href="https://colorlib.com" target="_blank">Colorlib</a>
		<!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. --></p>
						</div>
					</div>
				</div>
			</footer>

		</div><!-- END COOLIB- -->

	</div><!-- END COOLIB-PAGE -->



	<!-- loader -->
	<div id="ftco-loader" class="show fullscreen"><svg class="circular" width="48px" height="48px"><circle class="path-bg" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke="#eeeeee"/><circle class="path" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke-miterlimit="10" stroke="#F96D00"/></svg></div>


	<script src="js/jquery.min.js"></script>
	<script src="js/jquery-migrate-3.0.1.min.js"></script>
	<script src="js/popper.min.js"></script>
	<script src="js/bootstrap.min.js"></script>
	<script src="js/jquery.easing.1.3.js"></script>
	<script src="js/jquery.waypoints.min.js"></script>
	<script src="js/jquery.stellar.min.js"></script>
	<script src="js/owl.carousel.min.js"></script>
	<script src="js/jquery.magnific-popup.min.js"></script>
	<script src="js/aos.js"></script>
	<script src="js/jquery.animateNumber.min.js"></script>
	<script src="js/bootstrap-datepicker.js"></script>
	<script src="js/jquery.timepicker.min.js"></script>
	<script src="js/scrollax.min.js"></script>
	<script src="https://maps.googleapis.com/maps/api/js?key=AIzaSyBVWaKrjvy3MaE7SQ74_uJiULgl1JY0H2s&sensor=false"></script>
	<script src="js/google-map.js"></script>
	<script src="js/main.js"></script>

	</body>
</html>
