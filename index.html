<!DOCTYPE html>
<html lang="en">
	<head>
        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-138977761-1"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());

          gtag('config', 'UA-138977761-1');
        </script>

		<title>Wei Liu</title>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

		<link href="https://fonts.googleapis.com/css?family=Poppins:300,400,500,600,700" rel="stylesheet">
		<link href="https://fonts.googleapis.com/css?family=Montserrat:300,400,500,700" rel="stylesheet">

		<link rel="stylesheet" href="css/open-iconic-bootstrap.min.css">
		<link rel="stylesheet" href="css/animate.css">
		<!-- <link rel="stylesheet" href="css/main.css" /> -->
		<link rel="stylesheet" href="css/owl.carousel.min.css">
		<link rel="stylesheet" href="css/owl.theme.default.min.css">
		<link rel="stylesheet" href="css/magnific-popup.css">

		<link rel="stylesheet" href="css/aos.css">

		<link rel="stylesheet" href="css/ionicons.min.css">

		<link rel="stylesheet" href="css/bootstrap-datepicker.css">
		<link rel="stylesheet" href="css/jquery.timepicker.css">
		<link rel="stylesheet" href="css/academicons.min.css"/>
		<link rel="stylesheet" href="css/academicons.css"/>
		<link rel="stylesheet" href="css/flaticon.css">
		<link rel="stylesheet" href="css/icomoon.css">
		<link rel="stylesheet" href="css/style.css">
	</head>


	<body>
	<div id="coolib-page">

		<a href="#" class="js-coolib-nav-toggle coolib-nav-toggle"><i></i></a>


		<!-- Aside Bar -->
		<aside id="coolib-aside" role="complementary" class="js-fullheight text-center">
			<h1 id="coolib-logo"><a href="index.html">Wei Liu<span>.</span></a></h1>
			<nav id="coolib-main-menu" role="navigation">
				<ul>
					<li><a class='top-item' href="#front">Home</a></li>
					<li><a href="#projects">Projects</a></li>
					<li><a href="#experience">Experience</a></li>
					<li><a href="#publications">Publications</a></li>
					<li><a href="#honor">Honor</a></li>
					<li><a class='bottom-item' href="#footer">Contact</a></li>
				</ul>
			</nav>

			<div class="coolib-footer">
				<!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
				<p style='color:lightgray'>Copyright &copy;<script>document.write(new Date().getFullYear());</script> All rights reserved | This template is powered by <a style='color:#AAAAAA' href="https://colorlib.com" target="_blank">Colorlib</a></p>
			</div>
		</aside> <!-- END COOLIB-ASIDE -->



		<!-- Main page -->
		<div id="coolib-main">


			<!-- Front page -->
			<div id='front' class="hero-wrap js-fullheight" style="background-image: url(images/TimeToDisco_2.png); background-position: left" data-stellar-background-ratio="0.5">
				<div class="overlay"></div>
				<div class="js-fullheight d-flex justify-content-center align-items-center">
					<div class="col-md-8 text text-center">
						<div class="img mb-4" style="background-image: url(images/me.jpeg);"></div>
						<div class="desc">
							<h2 class="subheading">Hello I'm</h2>
							<h1 class="mb-4">Wei Liu</h1>
							<p class="mb-4">I am currently a research scientist at Seed Vision team, ByteDance Inc. I received my bachelor and Ph.D. from Harbin Institute of Technology, Harbin, China in 2016 and 2020, respectively. From 2017 to 2019, I was a visiting student at the Ohio State University, Columbus, USA. My main research interests include: Image/Video Generation, Multimodal Generation, Image Enhancement and Domain Adaptation.</p>
							<!-- <p><a target="_blank" href="static/CV.pdf" class="btn-custom">More About Me (CV) <span class="ion-ios-arrow-forward"></span></a></p> --> 
							<p><span class="icon icon-envelope"></span> &nbsp liuwei.jikun@bytedance.com
								&nbsp | &nbsp <a href="https://www.linkedin.com/in/%E7%8E%AE-%E5%88%98-791a52196/" class="icon icon-linkedin"></a>
								&nbsp <a href="https://github.com/liujikun" class="icon icon-github"></a>
								&nbsp<a href="https://scholar.google.com.hk/citations?user=Ypp0xoAAAAAJ&hl=zh-CN&authuser=1" class="icon icon-school"></a><br>
							<!-- <p><a class="icon fa-envelope"><span class="label">Email</span></a> &nbsp liuwei.jikun [at] bytedance [dot] com
								&nbsp | &nbsp <a href="https://www.linkedin.com/in/%E7%8E%AE-%E5%88%98-791a52196/" class="icon fa-linkedin-square fa-lg"><span class="label">LinkedIn</span></a>
								&nbsp <a href="https://github.com/liujikun" class="icon fa-github"><span class="label">github</span></a>
							&nbsp &nbsp<a href="https://scholar.google.com.hk/citations?user=Ypp0xoAAAAAJ&hl=zh-CN&authuser=1" class="ai_icon ai-google-scholar-square ai-lg"></a><br> -->

						</div>
					</div>
				</div>
			</div>

			<!-- Publication -->
			<section class="ftco-section">
				<div id='projects' class="container">
					<div class="row justify-content-center mb-5 pb-2">
						<div class="col-md-7 heading-section text-center ftco-animate">
							<h2 class="mb-4">Projects</h2>
						</div>
					</div>
					<div class="row">
						<div class="col-md-6">
							<div class="blog-entry ftco-animate">
								<div class='img-box'><div href="#" class="img img-2" style="background-image: url(images/seedream4.0.png);
									background-size: 100%;"></div></div>
								<div class="text text-2 pt-2 mt-3">
									<span class="category mb-3 d-block">Text2Image Generation, RL</span>
									<h5>Seedream 4.0: Toward Next-generation Multimodal Image Generation</h5>
									<p>Lead the construction of edit data and the joint-training algorithms for multimodal image generation.</p>
									<div class="meta-wrap">
											<p class="meta">
												<span><a target="_blank" href="https://arxiv.org/pdf/2509.20427">paper</a></span>
												<span><a target="_blank" href="https://seed.bytedance.com/en/seedream4_0">github</a></span>
												<span><a href="https://mp.weixin.qq.com/s/HnWnK1iszcFUxrBJS9gIiA">新智元报道</a></span>
											</p>
									</div>
								</div>
							</div>
						</div><!-- END Entry -->
					<div class="row">
						<div class="col-md-6">
							<div class="blog-entry ftco-animate">
								<div class='img-box'><div href="#" class="img img-2" style="background-image: url(images/dancegrpo.png);
									background-size: 100%;"></div></div>
								<div class="text text-2 pt-2 mt-3">
									<span class="category mb-3 d-block">Text2Image Generation, RL</span>
									<h5>DanceGRPO: Unleashing GRPO on Visual Generation</h5>
									<p>DanceGRPO </p>
									<div class="meta-wrap">
											<p class="meta">
												<span><a target="_blank" href="https://arxiv.org/abs/2505.07818">paper</a></span>
												<span><a target="_blank" href="https://github.com/XueZeyue/DanceGRPO">github</a></span>
												<span><a href="https://mp.weixin.qq.com/s/jivb_FgsfdJSgV2tbDbNUA">机器之心报道</a></span>
											</p>
									</div>
								</div>
							</div>
						</div><!-- END Entry -->
					<div class="row">
						<div class="col-md-6">
							<div class="blog-entry ftco-animate">
								<div class='img-box'><div href="#" class="img img-2" style="background-image: url(images/seedream3_overall.png);
									background-size: 100%;"></div></div>
								<div class="text text-2 pt-2 mt-3">
									<span class="category mb-3 d-block">Text2Image Generation</span>
									<h5>Seedream 3.0 Technical Report</h5>
									<p>Leading the full pipline of post-training.</p>
									<p>SeeDream 3.0 </p>
									<div class="meta-wrap">
											<p class="meta">
												<span><a target="_blank" href="https://arxiv.org/pdf/2504.11346">技术报告</a></span>
												<span><a href="https://mp.weixin.qq.com/s/GcmIQL78fIl-dobAsqbfeg">机器之心报道</a></span>
											</p>
									</div>
								</div>
							</div>
						</div><!-- END Entry -->
						<div class="col-md-6">
							<div class="blog-entry ftco-animate">
								<div class='img-box'><div href="#" class="img img-2" style="background-image: url(images/Seedream2.0.png);
									background-size: 100%;"></div></div>
								<div class="text text-2 pt-2 mt-3">
									<span class="category mb-3 d-block">Text2Image Generation</span>
									<h5>Seedream 2.0: A Native Chinese-English Bilingual Image Generation Foundation Model</h5>
									<p>Leading the construction of training data and the development of algorithms for post-training.</p>
									<p>SeeDream 2.0 </p>
									<div class="meta-wrap">
											<p class="meta">
												<span><a target="_blank" href="https://arxiv.org/pdf/2503.07703">技术报告</a></span>
												<span><a href="https://mp.weixin.qq.com/s/bM7RYbCqAd45Tts5qKpONA">机器之心报道</a></span>
											</p>
									</div>
								</div>
							</div>
						</div><!-- END Entry -->
						<div class="col-md-6">
							<div class="blog-entry ftco-animate">
								<div class='img-box'><div href="#" class="img img-2" style="background-image: url(images/vmix.jpg);
									background-size: 100%;"></div></div>
								<div class="text text-2 pt-2 mt-3">
									<span class="category mb-3 d-block">Multimodal Generation</span>
									<h5>VMix: Improving Text-to-Image Diffusion Model with Cross-Attention Mixing Control</h5>
									<p><span> Shaojin Wu, Fei Ding, Mengqi Huang, <span class='me'>Wei Liu</span>, Qian He</span></p>
									<p>Submitted </p>
									<div class="meta-wrap">
											<p class="meta">
												<span><a target="_blank" href="https://arxiv.org/abs/2412.20800v1">pdf</a></span>
												<span><a target="_blank" href="https://vmix-diffusion.github.io/VMix/">demo</a></span>
												<span><a href="https://mp.weixin.qq.com/s/LZCFJrjcsmuw-PPBLdxFrg">相关报道</a></span>
											</p>
									</div>
								</div>
							</div>
						</div><!-- END Entry -->
						<div class="col-md-6">
							<div class="blog-entry ftco-animate">
								<div class='img-box'><div href="#" class="img img-2" style="background-image: url(images/XMP-font-demo1.gif);
									background-size: 100%;"></div></div>
								<div class="text text-2 pt-2 mt-3">
									<span class="category mb-3 d-block">Font Generative, Multimodal Generation</span>
									<h5>XMP-Font: Self-Supervised Cross-Modality Pre-training for Few-Shot Font Generation</h5>
									<p><span class='me'>Wei Liu</span>, Fangyue Liu, Fei Ding, Qian He, Zili Yi</p>
									<p>CVPR, 2022 </p>
									<div class="meta-wrap">
											<p class="meta">
												<span><a target="_blank" href="https://arxiv.org/pdf/2204.05084.pdf">pdf</a></span>
												<span><a target="_blank" href="https://github.com/liujikun/XMP-Font">github</a></span>
												<span><a href="XMP-Font.html">details</a></span>
												<span><a href="https://mp.weixin.qq.com/s/6T-3dSxERNDBrKmLO8DwvQ">火山引擎报道</a></span>
											</p>
									</div>
								</div>
							</div>
						</div><!-- END Entry -->
						<div class="col-md-6">
							<div class="blog-entry ftco-animate">
								<div class='img-box'><div href="#" class="img img-2" style="background-image: url(images/denoising.png);
									background-size: 100%;"></div></div>
								<div class="text text-2 pt-2 mt-3">
									<span class="category mb-3 d-block">Image Enhancement, Denoising</span>
									<h5>Densely self-guided wavelet network for image denoising</h5>
									<p><span class='me'>Wei Liu</span>, Yuzhi Zhao, Qiong Yan</p>
									<p>CVPR Workshop, 2020</p>
									<div class="meta-wrap">
											<p class="meta">
												<span><a target="_blank" href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w31/Liu_Densely_Self-Guided_Wavelet_Network_for_Image_Denoising_CVPRW_2020_paper.pdf">pdf</a></span>
												<span><a target="_blank" href="
													https://github.com/liujikun/Densely-Self-guided-Wavelet-Network-for-Image-Denoising">github</a></span>
											</p>
									</div>
								</div>
							</div>
						</div><!-- END Entry -->
						<div class="col-md-6">
							<div class="blog-entry ftco-animate">
								<div class='img-box'><div href="#" class="img img-2" style="background-image: url(images/dreamtuner.png);
									background-size: 80%;"></div></div>
								<div class="text text-2 pt-2 mt-3">
									<span class="category mb-3 d-block">AIGC, Diffusion model</span>
									<h5>DreamTuner: Single Image is Enough for Subject-Driven Generation</h5>
									<p><span> Miao Hua, Jiawei Liu, Fei Ding, <span class= 'me'>Wei Liu</span></p>
									<div class="meta-wrap">
											<p class="meta">
												<span><a target="_blank" href="https://arxiv.org/pdf/2312.13691.pdf">pdf</a></span>
												<span><a href="https://dreamtuner-diffusion.github.io">details</a></span>
												<span><a href="https://mp.weixin.qq.com/s/XJ3NMQRHoumtnTyHGFQH1w">相关报道</a></span>
												<span><a href="https://corleone-huang.github.io/realcustom/"> Another IP maintenance paper led by me, CVPR2024</a></span>
											</p>
									</div>
								</div>
							</div>
						</div><!-- END Entry -->
						<div class="col-md-6">
							<div class="blog-entry ftco-animate">
								<div class='img-box'><div href="#" class="img img-2" style="background-image: url(images/DreamIdentity.png);
									background-size: 100%;"></div></div>
								<div class="text text-2 pt-2 mt-3">
									<span class="category mb-3 d-block">AIGC, Diffusion Model</span>
									<h5>DreamIdentity: Improved Editability for Efficient Face-identity Preserved Image Generation</h5>
									<p><span> Zhuowei Chen, Shancheng Fang,</span>  <span class='me'>Wei Liu</span></p>
									<p>AAAI, 2024 </p>
									<div class="meta-wrap">
											<p class="meta">
												<span><a target="_blank" href="https://arxiv.org/abs/2307.00300">pdf</a></span>
												<span><a href="https://dreamidentity.github.io/">details</a></span>
											</p>
									</div>
								</div>
							</div>
						</div><!-- END Entry -->
						<div class="col-md-6">
							<div class="blog-entry ftco-animate">
								<div class='img-box'><div href="#" class="img img-2" style="background-image: url(images/designbooster.png);
									background-size: 100%;"></div></div>
								<div class="text text-2 pt-2 mt-3">
									<span class="category mb-3 d-block">AIGC, Diffusion Model</span>
									<h5>Design Booster: A Text-Guided Diffusion Model for Image Translation with Spatial Layout Preservation</h5>
									<p><span> Shiqi Sun, Shancheng Fang, Qian He,</span>  <span class='me'>Wei Liu</span></p>
									<div class="meta-wrap">
											<p class="meta">
												<span><a target="_blank" href="https://arxiv.org/abs/2302.02284">pdf</a></span>
												<span><a href="https://mp.weixin.qq.com/s/8qaIm7zUbIPkztwjAJaJJw">相关落地-量子位报道</a></span>
											</p>
									</div>
								</div>
							</div>
						</div><!-- END Entry -->
						<div class="col-md-6">
							<div class="blog-entry ftco-animate">
								<div class='img-box'><div href="#" class="img img-2" style="background-image: url(images/CFFT-GAN.png);
									background-size: 100%;"></div></div>
								<div class="text text-2 pt-2 mt-3">
									<span class="category mb-3 d-block">AIGC, GAN, Smart Edit</span>
									<h5>CFFT-GAN: Cross-domain Feature Fusion Transformer for Exemplar-based Image Translation</h5>
									<p><span> Tianxiang Ma, Bingchuan Li,</span>  <span class='me'>Wei Liu</span></p>
									<div class="meta-wrap">
											<p class="meta">
												<span><a target="_blank" href="https://arxiv.org/pdf/2302.01608.pdf">pdf</a></span>
												<span><a href="https://www.jiqizhixin.com/articles/2023-02-10-7">机器之心报道</a></span>
											</p>
									</div>
								</div>
							</div>
						</div><!-- END Entry -->
					</div>
				</div>




			<!-- Experience -->
				<div id='experience' class="container">
					<div class="row justify-content-center mb-5 pb-2">
						<div class="col-md-7 heading-section text-center ftco-animate">
							<h2 class="mb-4">Experience</h2>
						</div>
					</div>
					<div class="row">

						<div class="col-md-3">
							<div class="blog-entry ftco-animate">
								<a target="_blank" href="https://www.hit.edu.cn/"><div href="#" class="img img-3" style="background-image: url(images/hit.jpeg);
									background-size: 200px;"></div></a>
								<div class="text text-2 pt-2 mt-3">
									<span class="category mb-3 d-block">Education</span>
									<h5>Harbin Institute of Technology</h5>
									<p><span class='me'>Bachelor, PhD, 2012-2020</p>
									<p>Topic: Image Generation, Domain Adaptation, Semantic Segmentation</p>
								</div>
							</div>
						</div><!-- END Entry -->

						<div class="col-md-3">
							<div class="blog-entry ftco-animate">
								<a target="_blank" href="https://www.sensetime.com/cn"><div href="#" class="img img-3" style="background-image: url(images/sensetime.jpeg);
									background-size: 200px;"></div></a>
								<div class="text text-2 pt-2 mt-3">
									<span class="category mb-3 d-block">Internship</span>
									<h5>SenseTime MIG</h5>
									<p><span class='me'>Research Intern, 2019-2020</p>
									<p>Topic: Image Enhancement, Image Denoising, Image Deglow, Image Generation</p>
								</div>
							</div>
						</div><!-- END Entry -->

						<div class="col-md-3">
							<div class="blog-entry ftco-animate">
								<a target="_blank" href="https://www.bytedance.com/"><div href="#" class="img img-3" style="background-image: url(images/bytedance.jpg);
									background-size: 200px;"></div></a>
								<div class="text text-2 pt-2 mt-3">
									<span class="category mb-3 d-block">Research Scientist</span>
									<h5>ByteDance Inc.</h5>
									<p><span class='me'>2020 to present</p>
									<p>Topic: Content Generation, Multimodal Generation, Smart Editing, Smart Design</p>
								</div>
							</div>
						</div><!-- END Entry -->

						<div class="col-md-3">
							<div class="blog-entry ftco-animate">
								<a target="_blank" href="https://www.osu.edu/"><div href="#" class="img img-3" style="background-image: url(images/OSU.png);
									background-size: 200px;"></div></a>
								<div class="text text-2 pt-2 mt-3">
									<span class="category mb-3 d-block">Education</span>
									<h5>The Ohio State University</h5>
									<p><span class='me'>Visiting student, 2017-2019</p>
									<p>Topic: Domain Adaptation, Stereo Matching, Semantic Segmentation</p>
								</div>
							</div>
						</div><!-- END Entry -->

					</div>
				</div>

				<div id='publications' class="container">
					<div class="row justify-content-center mb-5 pb-2">
						<div class="col-md-7 heading-section text-center ftco-animate">
							<h2 class="mb-4">Publications</h2>
						</div>
					</div>
					<div class="row">

						<div id="wrapper">
							<section id="item10" class="item">

			
								<h2><font size = "5">Image Generation</font></h2>
								<p>
									<ul>
										<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://arxiv.org/abs/2307.00300">DreamIdentity: Improved Editability for Efficient Face-identity Preserved Image Generation</a></span><br/>
											Zhuowei Chen, Shancheng Fang, <u>Wei Liu*</u>， Qian He, Mengqi Huang, Yongdong Zhang, Zhendong Mao<br><span style="color:#3D3D3D"> AAAI Conference on Artificial Intelligence (AAAI-24) <a target="_blank" href="https://dreamidentity.github.io/">proj demo</a> <a target="_blank" href="http://www.citnews.com.cn/news/202307/163467.html">相关报道</a></span></li>
									</ul>
									<ul>
										<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://arxiv.org/pdf/2312.13691.pdf">DreamTuner: Single Image is Enough for Subject-Driven Generation</a></span><br/>
											Miao Hua, Jiawei Liu, Fei Ding, <u>Wei Liu*</u><br><span style="color:#3D3D3D"> arxiv  <a target="_blank" href="https://dreamtuner-diffusion.github.io/">proj demo</a> <a target="_blank" href="https://mp.weixin.qq.com/s/XJ3NMQRHoumtnTyHGFQH1w">相关报道</a></span></li>
									</ul>
									<ul>
										<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://arxiv.org/abs/2302.02284">Design Booster: A Text-Guided Diffusion Model for Image Translation with Spatial Layout Preservation</a></span><br/>
											Shiqi Sun, Shancheng Fang, Qian He, <u>Wei Liu*</u><br><span style="color:#3D3D3D">The IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR) 2023 (submitted) <a target="_blank" href="https://mp.weixin.qq.com/s/8qaIm7zUbIPkztwjAJaJJw">量子位报道</a></span></li>
									</ul>
									<ul>
										<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://arxiv.org/pdf/2204.05084.pdf">XMP-Font: Self-Supervised Cross-Modality Pre-training for Few-Shot Font Generation</a></span><br/>
											<u>Wei Liu</u>, Fangyue Liu, Fei Ding, Qian He, Zili Yi<br><span style="color:#3D3D3D">The IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR) 2022 &nbsp <a target="_blank" href="https://mp.weixin.qq.com/s/6T-3dSxERNDBrKmLO8DwvQ">火山引擎报道</a></span></li>
									</ul>
									<ul>
										<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://arxiv.org/pdf/2203.00386.pdf">CLIP-GEN: Language-Free Training of a Text-to-Image Generator with CLIP</a></span><br/>
											Zihao Wang, <u>Wei Liu</u>,, Qian He, Xinglong Wu, Zili Yi<br><span style="color:#3D3D3D">Submitted to ECCV 2022 &nbsp <a target="_blank" href="https://mp.weixin.qq.com/s/UAAVTI9zVhRDcMwUSW5l_Q">量子位报道</a></span></li>
									</ul>
									<ul>
										<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://arxiv.org/abs/2302.01608">CFFT-GAN: Cross-domain Feature Fusion Transformer for Exemplar-based Image Translation</a></span><br/>
											Tianxiang Ma, Bingchuan Li, <u>Wei Liu</u>, Miao Hua, Jing Dong, Tieniu Tan<br><span style="color:#3D3D3D">AAAI 2023 &nbsp <a target="_blank" href="https://www.jiqizhixin.com/articles/2023-02-10-7">机器之心报道</a></span></li>
									</ul>
									<ul>
										<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://arxiv.org/abs/2301.13402">ReGANIE: Rectifying GAN Inversion Errors for Accurate Real Image Editing</a></span><br/>
											Bingchuan Li, Tianxiang Ma, Peng Zhang, Miao Hua, <u>Wei Liu</u>, Qian He, Zili Yi<br><span style="color:#3D3D3D">AAAI 2023 &nbsp <a target="_blank" href="https://www.jiqizhixin.com/articles/2023-02-10-7">机器之心报道</a></span></li>
									</ul>
									<ul>
										<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://arxiv.org/pdf/2109.10737.pdf">DyStyle: Dynamic Neural Network for Multi-Attribute-Conditioned Style Editing</a></span><br/>
											Bingchuan Li, Shaofei Cai, <u>Wei Liu</u>, Peng Zhang, Miao Hua, Qian He, Zili Yi<br><span style="color:#3D3D3D">WACV 2023</span></li>
									</ul>
									<ul>
										<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://arxiv.org/pdf/2204.09962.pdf">ChildPredictor: A Child Face Prediction Framework with Disentangled Learning</a></span><br>
											Yuzhi Zhao, Lai-Man Po, Xuehui Wang, Qiong Yan, Wei Shen, Yujia Zhang, <u>Wei Liu</u>, Chun-Kit Wong, Chiu-Sing Pang, Weifeng Ou, Wing Yin Yu, Buhua Liu<br><span style="color:#3D3D3D">IEEE Transactions on Multimedia, 2022 (IF=6.51)</span></li>
									</ul>
								</p>
							</section>
								<section id="item9" class="item">
			
									<h2><font size = "5">Image Enhancement</font></h2>
									<p>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w31/Liu_Densely_Self-Guided_Wavelet_Network_for_Image_Denoising_CVPRW_2020_paper.pdf">Densely self-guided wavelet network for image denoising</a></span><br/>
											<u>Wei Liu</u>, Qiong Yan, Yuzhi Zhao<br><span style="color:#3D3D3D">The IEEE / CVF Computer Vision and Pattern Recognition Conference Workshop (CVPRW) 2020</span></li>
			
			
										</ul>
									</p>
								</section>
								<section id="item8" class="item">
									<h2><font size = "5">Domain Adaptation</font></h2>
			
									<p>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://www.researchgate.net/profile/Rongjun-Qin/publication/347005550_Bispace_Domain_Adaptation_Network_for_Remotely_Sensed_Semantic_Segmentation/links/5fe3b5c845851553a0e62dd6/Bispace-Domain-Adaptation-Network-for-Remotely-Sensed-Semantic-Segmentation.pdf">Bispace domain adaptation network for remotely sensed semantic segmentation</a></span><br>
											<u>Wei Liu</u>, Fulin Su, Xinfei Jin, Hongxu Li, Rongjun Qin<br><span style="color:#3D3D3D">IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, 2020 (IF=6.87)</span></li>
										</ul>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://ieeexplore.ieee.org/abstract/document/8960415">	
												A multikernel domain adaptation method for unsupervised transfer learning on cross-source and cross-region remote sensing data classification</a></span><br>
											<u>Wei Liu</u>, Rongjun Qin<br><span style="color:#3D3D3D">IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, 2020 (IF=6.87)</span></li>
										</ul>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://www.tandfonline.com/doi/abs/10.1080/01431161.2020.1736727">	
												A novel unsupervised adversarial domain adaptation network for remotely sensed scene classification</a></span><br>
											<u>Wei Liu</u>, Fulin Su<br><span style="color:#3D3D3D">International Journal of Remote Sensing, 2020 (IF=3.36)</span></li>
										</ul>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://ieeexplore.ieee.org/abstract/document/8932673">	
												Unsupervised Adversarial Domain Adaptation Network for Semantic Segmentation</a></span><br>
											<u>Wei Liu</u>, Fulin Su<br><span style="color:#3D3D3D">IEEE Geoscience and Remote Sensing Letters, 2019 (IF=5.14)</span></li>
										</ul>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://www.tandfonline.com/doi/abs/10.1080/2150704X.2019.1597295">	
												Weakly supervised classification of time-series of very high resolution remote sensing images by transfer learning</a></span><br>
											<u>Wei Liu</u>, Rongjun Qin, Fulin Su<br><span style="color:#3D3D3D">Remote Sensing Letters, 2019 (IF=2.91)</span></li>
										</ul>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://www.researchgate.net/profile/Rongjun-Qin/publication/325256383_An_Unsupervised_Domain_Adaptation_Method_for_Multi-Modal_Remote_Sensing_Image_Classification/links/5c194c72a6fdccfc705813ed/An-Unsupervised-Domain-Adaptation-Method-for-Multi-Modal-Remote-Sensing-Image-Classification.pdf">	
												An unsupervised domain adaptation method for multi-modal remote sensing image classification</a></span><br>
											<u>Wei Liu</u>, Rongjun Qin, Fulin Su, Kun Hu<br><span style="color:#3D3D3D">2018 26th International Conference on Geoinformatics (Best Student Paper 3rd plcae)</span></li>
										</ul>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://ieeexplore.ieee.org/abstract/document/8898334">	
												Unsupervised Transfer Learning Using for Multi-Model Remote Sensing Data Classification</a></span><br>
											<u>Wei Liu</u>, Rongjun Qin<br><span style="color:#3D3D3D">IEEE International Geoscience and Remote Sensing Symposium (IGARSS) 2019</span></li>
										</ul>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://ieeexplore.ieee.org/abstract/document/9547210">	
												Large-Scale Land Cover Mapping of Satellite Images Using Ensemble of Random Forests — IEEE Data Fusion Contest 2020 Track 1</a></span><br>
											Huijun Chen, <u>Wei Liu</u>, Changlin Xiao, Rongjun Qin<br><span style="color:#3D3D3D">IEEE International Geoscience and Remote Sensing Symposium (IGARSS) 2020</span></li>
										</ul>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://ieeexplore.ieee.org/abstract/document/9547214">	
												Large-Scale Land Cover Mapping of Satellite Images Using Ensemble of Random Forests with Multi-Resolution Label–IEEE Data Fusion Contest 2020 Track 2</a></span><br>
											Huijun Chen, Changlin Xiao, <u>Wei Liu</u>, Rongjun Qin<br><span style="color:#3D3D3D">IEEE International Geoscience and Remote Sensing Symposium (IGARSS) 2020</span></li>
										</ul>
									</p>
								</section>
			
								<section id="item7" class="item">
									<h2><font size = "5">Stereo Matching</font></h2>
									<p>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://www.tandfonline.com/doi/abs/10.1080/2150704X.2020.1723168">A window size selection network for stereo dense image matching</a></span><br/>
											Xu Huang, <u>Wei Liu</u> (The first two authors contributed equally), Rongjun Qin<br><span style="color:#3D3D3D">International Journal of Remote Sensing, 2020 (IF=3.36)</span></li>
										</ul>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://www.mdpi.com/2072-4292/12/19/3138">Stereo dense image matching by adaptive fusion of multiple-window matching results</a></span><br/>
												Yilong Han, <u>Wei Liu</u> , Xu Huang, Shugen Wang, Rongjun Qin<br><span style="color:#3D3D3D">Remote Sensing, 2020 (IF=4.85)</span></li>
										</ul>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://ieeexplore.ieee.org/abstract/document/8900588">Semantic 3D reconstruction using multi-view high-resolution satellite images based on U-Net and image-guided depth fusion</a></span><br/>
												Rongjun Qin, Xu Huang, <u>Wei Liu</u>, Changlin Xiao<br><span style="color:#3D3D3D">IEEE International Geoscience and Remote Sensing Symposium (IGARSS) 2019</span></li>
										</ul>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://ieeexplore.ieee.org/abstract/document/8900262">Pairwise stereo image disparity and semantics estimation with the combination of U-Net and pyramid stereo matching network</a></span><br/>
												Rongjun Qin, Xu Huang, <u>Wei Liu</u>, Changlin Xiao<br><span style="color:#3D3D3D">IEEE International Geoscience and Remote Sensing Symposium (IGARSS) 2019</span></li>
										</ul>
									</p>
								</section>

								<section id="item6" class="item">
									<h2><font size = "5">Others</font></h2>
									<p>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://www.researchgate.net/profile/Xi-Chen-311/publication/317129244_Semisupervised_Multiview_Feature_Selection_for_VHR_Remote_Sensing_Images_With_Label_Learning_and_Automatic_View_Generation/links/5a75cd6345851541ce58735b/Semisupervised-Multiview-Feature-Selection-for-VHR-Remote-Sensing-Images-With-Label-Learning-and-Automatic-View-Generation.pdf">Semisupervised multiview feature selection for VHR remote sensing images with label learning and automatic view generation</a></span><br/>
												Xi Chen, <u>Wei Liu</u>, Fulin Su, Gongjian Zhou<br><span style="color:#3D3D3D">IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2017 (IF=4.54)</span></li>
										</ul>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://ieeexplore.ieee.org/abstract/document/7729612">Semi-supervised multiview feature selection with label learning for VHR remote sensing images</a></span><br/>
												Xi Chen, <u>Wei Liu</u>, Fulin Su, Guofan Shao<br><span style="color:#3D3D3D">IEEE International Geoscience and Remote Sensing Symposium (IGARSS) 2016</span></li>
										</ul>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w31/Zhao_Hierarchical_Regression_Network_for_Spectral_Reconstruction_From_RGB_Images_CVPRW_2020_paper.pdf">Hierarchical regression network for spectral reconstruction from RGB images</a></span><br/>
												Yuzhi Zhao, Lai-Man Po, Qiong Yan, <u>Wei Liu</u>, Tingyu Lin<br><span style="color:#3D3D3D">The IEEE / CVF Computer Vision and Pattern Recognition Conference Workshop (CVPRW) 2020</span></li>
										</ul>
										<ul>
											<li><span style="font-weight:bold;color:#3D3D3D"><a class="nonblock" href="https://ieeexplore.ieee.org/abstract/document/8557172">High-frequency jitter detection by registration error curve of high-resolution multi-spectral satellite image</a></span><br/>
												Kun Hu, Yongjun Zhang, <u>Wei Liu</u><br><span style="color:#3D3D3D">2018 26th International Conference on Geoinformatics</span></li>
										</ul>
									</p>
								</section>
								</section>
			
						</div>
						

					</div>
				</div>
				<div id='honor' class="container">
					<div class="row justify-content-center mb-5 pb-2">
						<div class="col-md-7 heading-section text-center ftco-animate">
							<h2 class="mb-4">Honor</h2>
						</div>
					</div>
					<p>
						&nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp <span class="icon icon-trophy"></span> &nbsp <span style="margin-left: 150px;margin: 0 auto;text-align: center;font-weight:bold;color:#A42D00">NTIRE 2020 Spectral Reconstruction Challenge Real World Track 1st place (1/95)</span>
						<br /> &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp <span class="icon icon-trophy"></span> &nbsp <span style="margin-left: 150px;margin: 0 auto;text-align: center;font-weight:bold;color:#A42D00">2020 IEEE GRSS Data Fusion Contest Global Land Cover Mapping with Weak Supervision 1st place (1/169)</span>
						<br /> &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp <span class="icon icon-trophy"></span> &nbsp <span style="margin-left: 150px;margin: 0 auto;text-align: center;font-weight:bold;color:#A42D00">2019 IEEE GRSS Data Fusion Contest Pairwise Semantic Stereo Challenge 2nd place (2/144)</span>
						<br /> &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp  &nbsp <span class="icon icon-trophy"></span> &nbsp <span style="margin-left: 150px;margin: 0 auto;text-align: center;font-weight:bold;color:#A42D00">2019 IEEE GRSS Data Fusion Contest Multiview Semantic Stereo Challenge 2nd place (2/123)</span>
					</p>
				</div>
				<br />
				<br />
				<br />
				<br />
			</section>

			<!-- Footer -->
			<footer id='footer' class="ftco-footer ftco-bg-dark ftco-section">
				<div class="container px-md-5">
					<div class="row mb-5">
						<div class="col-md">
							<div class="ftco-footer-widget mb-4 ml-md-4">
								<h2 class="ftco-heading-2">Category</h2>
								<ul class="list-unstyled categories">
									<li><a href="#front">Home </a></li>
									<li><a href="#projects">Projects </a></li>
									<li><a href="#experience">Experience </a></li>
									<li><a href="#pubications">Pubications </a></li>
									<li><a href="#honor">Honor </a></li>
									<li><a href="#footer">Contact </a></li>
								</ul>
							</div>
						</div>
						<div class="col-md">
						</div>
						<div class="col-md">
							<div class="ftco-footer-widget mb-4">
								<h2 class="ftco-heading-2">Have a Questions?</h2>
								<div class="block-23 mb-3">
									<ul>
										<li><span class="icon icon-map-marker"></span>
											<p>Beijing, China</p>
										</li>
										<!-- <li><a href="#"><span class="icon icon-phone"></span><span class="text">+1 517 220 8402</span></a></li> -->
										<li><a href="#"><span class="icon icon-envelope"></span><span class="text">liuwei.jikun@bytedance.com</span></a></li>
										<li><a href="#"><span class="icon icon-envelope"></span><span class="text">liujikun63@gmail.com</span></a></li>
									</ul>
								</div>
							</div>
						</div>
					</div>
					<div class="row">
						<div class="col-md-12">

							<p><!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
		Copyright &copy;<script>document.write(new Date().getFullYear());</script> All rights reserved | This template is made with <i class="icon-heart" aria-hidden="true"></i> by <a target="_blank" href="https://colorlib.com" target="_blank">Colorlib</a>
		<!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. --></p>
						</div>
					</div>
				</div>
			</footer>

		</div><!-- END COOLIB- -->

	</div><!-- END COOLIB-PAGE -->



	<!-- loader -->
	<div id="ftco-loader" class="show fullscreen"><svg class="circular" width="48px" height="48px"><circle class="path-bg" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke="#eeeeee"/><circle class="path" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke-miterlimit="10" stroke="#F96D00"/></svg></div>


	<script src="js/jquery.min.js"></script>
	<script src="js/jquery-migrate-3.0.1.min.js"></script>
	<script src="js/popper.min.js"></script>
	<script src="js/bootstrap.min.js"></script>
	<script src="js/jquery.easing.1.3.js"></script>
	<script src="js/jquery.waypoints.min.js"></script>
	<script src="js/jquery.stellar.min.js"></script>
	<script src="js/owl.carousel.min.js"></script>
	<script src="js/jquery.magnific-popup.min.js"></script>
	<script src="js/aos.js"></script>
	<script src="js/jquery.animateNumber.min.js"></script>
	<script src="js/bootstrap-datepicker.js"></script>
	<script src="js/jquery.timepicker.min.js"></script>
	<script src="js/scrollax.min.js"></script>
	<script src="https://maps.googleapis.com/maps/api/js?key=AIzaSyBVWaKrjvy3MaE7SQ74_uJiULgl1JY0H2s&sensor=false"></script>
	<script src="js/google-map.js"></script>
	<script src="js/main.js"></script>

	</body>
</html>
